{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>mucous_membrane</th>\n",
       "      <th>capillary_refill_time</th>\n",
       "      <th>...</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_appearance</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>surgical_lesion</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "      <th>cp_data</th>\n",
       "      <th>outcome</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>530001</td>\n",
       "      <td>38.1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>dark_cyanotic</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>3.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>533836</td>\n",
       "      <td>37.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>pale_cyanotic</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>529812</td>\n",
       "      <td>38.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>less_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>3.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>5124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>lived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>5262541</td>\n",
       "      <td>37.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cold</td>\n",
       "      <td>reduced</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>lived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>5299629</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal_pink</td>\n",
       "      <td>less_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>2.6</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>lived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  surgery    age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0     yes  adult           530001         38.1  132.0              24.0   \n",
       "1     yes  adult           533836         37.5   88.0              12.0   \n",
       "2     yes  adult           529812         38.3  120.0              28.0   \n",
       "3     yes  adult          5262541         37.1   72.0              30.0   \n",
       "4      no  adult          5299629         38.0   52.0              48.0   \n",
       "\n",
       "  temp_of_extremities peripheral_pulse mucous_membrane capillary_refill_time  \\\n",
       "0                cool          reduced   dark_cyanotic            more_3_sec   \n",
       "1                cool           normal   pale_cyanotic            more_3_sec   \n",
       "2                cool          reduced       pale_pink            less_3_sec   \n",
       "3                cold          reduced       pale_pink            more_3_sec   \n",
       "4              normal           normal     normal_pink            less_3_sec   \n",
       "\n",
       "   ... total_protein abdomo_appearance abdomo_protein surgical_lesion  \\\n",
       "0  ...           8.5     serosanguious            3.4             yes   \n",
       "1  ...          64.0     serosanguious            2.0             yes   \n",
       "2  ...           6.4     serosanguious            3.4             yes   \n",
       "3  ...           7.0            cloudy            3.9             yes   \n",
       "4  ...           7.3            cloudy            2.6              no   \n",
       "\n",
       "  lesion_1  lesion_2 lesion_3 cp_data     outcome  original  \n",
       "0     2209         0        0      no        died         0  \n",
       "1     2208         0        0      no  euthanized         0  \n",
       "2     5124         0        0      no       lived         0  \n",
       "3     2208         0        0     yes       lived         0  \n",
       "4        0         0        0     yes       lived         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('./train.csv')\n",
    "test=pd.read_csv('./test.csv')\n",
    "original=pd.read_csv(\"./horse.csv\")\n",
    "\n",
    "train.drop(columns=[\"id\"],inplace=True)\n",
    "test.drop(columns=[\"id\"],inplace=True)\n",
    "\n",
    "train_copy=train.copy()\n",
    "test_copy=test.copy()\n",
    "original_copy=original.copy()\n",
    "\n",
    "# cols=[f for f in train.columns if train[f].isna().sum()==0 and original[f].isna().sum()>0]\n",
    "# original=original.loc[original[cols].dropna().index.tolist()]\n",
    "# print(original.shape)\n",
    "\n",
    "original[\"original\"]=1\n",
    "\n",
    "train[\"original\"]=0\n",
    "test[\"original\"]=0\n",
    "\n",
    "train=pd.concat([train,original],axis=0)\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "\n",
    "train.loc[train['rectal_exam_feces'] == 'serosanguious', 'rectal_exam_feces'] = np.nan\n",
    "train.loc[train['peristalsis'] == 'distend_small', 'peristalsis'] = np.nan\n",
    "train.loc[train['nasogastric_reflux'] == 'slight', 'nasogastric_reflux'] = 'less_1_liter'\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesion_1_num(x):\n",
    "    if x!=0:\n",
    "        if len(str(x))==5 and int(str(x)[3:])!=10:\n",
    "            return int(str(x)[:2])\n",
    "        else:\n",
    "            return int(str(x)[0])\n",
    "    else:\n",
    "        return 0\n",
    "def lesion_2_num(x):\n",
    "    if x!=0:\n",
    "        return int(str(x)[1])\n",
    "    else:\n",
    "        return 0\n",
    "def lesion_3_num(x):\n",
    "    if x!=0:\n",
    "        if len(str(x))==2:\n",
    "            x=x*100\n",
    "        elif len(str(x))==3:\n",
    "            x=x*10\n",
    "        if len(str(x))==5:\n",
    "            return int(str(x)[3])\n",
    "        else: \n",
    "            return int(str(x)[2])\n",
    "    else:\n",
    "        return 0\n",
    "def lesion_4_num(x):\n",
    "    if x!=0:\n",
    "        if len(str(x))==2:\n",
    "            x=x*100\n",
    "        elif len(str(x))==3:\n",
    "            x=x*10\n",
    "        if len(str(x))==5 and int(str(x)[3:])!=10:\n",
    "            return int(str(x)[4:])\n",
    "        else:\n",
    "            return int(str(x)[3:])\n",
    "    else:\n",
    "        return 0\n",
    "lesion_1 = {\n",
    "    1: \"Gastric\",\n",
    "    2: \"Small_Intestine\",\n",
    "    3: \"Large_Colon\",\n",
    "    4: \"Large_Colon_and_Cecum\",\n",
    "    5: \"Cecum\",\n",
    "    6: \"Transverse_Colon\",\n",
    "    7: \"Rectum_Descending_Colon\",\n",
    "    8: \"Uterus\",\n",
    "    9: \"Bladder\",\n",
    "    11: \"All_Intestinal_Sites\",\n",
    "    12: \"Other_1\",\n",
    "    0:\"NA_1\"\n",
    "}\n",
    "lesion_2 = {\n",
    "    1: \"Simple\",\n",
    "    2: \"Strangulation\",\n",
    "    3: \"Inflammation\",\n",
    "    4: \"Other_2\",\n",
    "    0: \"Other_2\",\n",
    "    7: \"Other_2\",\n",
    "\n",
    "    \n",
    "}\n",
    "lesion_3 = {\n",
    "    1: \"Mechanical\",\n",
    "    2: \"Paralytic\",\n",
    "    0: \"NA3\",\n",
    "    3: \"Other_3\"\n",
    "    \n",
    "}\n",
    "lesion_4 = {\n",
    "    1: \"Obturation\",\n",
    "    2: \"Intrinsic\",\n",
    "    3: \"Extrinsic\",\n",
    "    4: \"Adynamic\",\n",
    "    5: \"Volvulus_Torsion\",\n",
    "    6: \"Intussusception\",\n",
    "    7: \"Thromboembolic\",\n",
    "    8: \"Hernia\",\n",
    "    9: \"Lipoma_Splenic_Incarceration\",\n",
    "    10: \"Displacement\",\n",
    "    0: \"NA4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Encode all the lesion data and map them based on their code'''\n",
    "train['lesion_1_1']=train['lesion_1'].apply(lesion_1_num).replace(lesion_1)\n",
    "test['lesion_1_1']=test['lesion_1'].apply(lesion_1_num).replace(lesion_1)\n",
    "\n",
    "train['lesion_1_2']=train['lesion_1'].apply(lesion_2_num).replace(lesion_2)\n",
    "test['lesion_1_2']=test['lesion_1'].apply(lesion_2_num).replace(lesion_2)\n",
    "\n",
    "train['lesion_1_3']=train['lesion_1'].apply(lesion_3_num).replace(lesion_3)\n",
    "test['lesion_1_3']=test['lesion_1'].apply(lesion_3_num).replace(lesion_3)\n",
    "\n",
    "train['lesion_1_4']=train['lesion_1'].apply(lesion_4_num).replace(lesion_4)\n",
    "test['lesion_1_4']=test['lesion_1'].apply(lesion_4_num).replace(lesion_4)\n",
    "\n",
    "'''----------------------------------------------------------------------'''\n",
    "train['lesion_2_1']=train['lesion_2'].apply(lesion_1_num).replace(lesion_1)\n",
    "test['lesion_2_1']=test['lesion_2'].apply(lesion_1_num).replace(lesion_1)\n",
    "\n",
    "train['lesion_2_2']=train['lesion_2'].apply(lesion_2_num).replace(lesion_2)\n",
    "test['lesion_2_2']=test['lesion_2'].apply(lesion_2_num).replace(lesion_2)\n",
    "\n",
    "train['lesion_2_3']=train['lesion_2'].apply(lesion_3_num).replace(lesion_3)\n",
    "test['lesion_2_3']=test['lesion_2'].apply(lesion_3_num).replace(lesion_3)\n",
    "\n",
    "train['lesion_2_4']=train['lesion_2'].apply(lesion_4_num).replace(lesion_4)\n",
    "test['lesion_2_4']=test['lesion_2'].apply(lesion_4_num).replace(lesion_4)\n",
    "\n",
    "'''Lesion codes'''\n",
    "train['lesion_1_1_num'] = train['lesion_1'].apply(lesion_1_num)  # .replace(lesion_1)\n",
    "test['lesion_1_1_num'] = test['lesion_1'].apply(lesion_1_num)  # .replace(lesion_1)\n",
    "\n",
    "train['lesion_1_2_num'] = train['lesion_1'].apply(lesion_2_num)  # .replace(lesion_2)\n",
    "test['lesion_1_2_num'] = test['lesion_1'].apply(lesion_2_num)  # .replace(lesion_2)\n",
    "\n",
    "train['lesion_1_3_num'] = train['lesion_1'].apply(lesion_3_num)  # .replace(lesion_3)\n",
    "test['lesion_1_3_num'] = test['lesion_1'].apply(lesion_3_num)  # .replace(lesion_3)\n",
    "\n",
    "train['lesion_1_4_num'] = train['lesion_1'].apply(lesion_4_num)  # .replace(lesion_4)\n",
    "test['lesion_1_4_num'] = test['lesion_1'].apply(lesion_4_num)  # .replace(lesion_4)\n",
    "\n",
    "'''----------------------------------------------------------------------'''\n",
    "\n",
    "train['lesion_2_1_num'] = train['lesion_2'].apply(lesion_1_num)  # .replace(lesion_1)\n",
    "test['lesion_2_1_num'] = test['lesion_2'].apply(lesion_1_num)  # .replace(lesion_1)\n",
    "\n",
    "train['lesion_2_2_num'] = train['lesion_2'].apply(lesion_2_num)  # .replace(lesion_2)\n",
    "test['lesion_2_2_num'] = test['lesion_2'].apply(lesion_2_num)  # .replace(lesion_2)\n",
    "\n",
    "train['lesion_2_3_num'] = train['lesion_2'].apply(lesion_3_num)  # .replace(lesion_3)\n",
    "test['lesion_2_3_num'] = test['lesion_2'].apply(lesion_3_num)  # .replace(lesion_3)\n",
    "\n",
    "train['lesion_2_4_num'] = train['lesion_2'].apply(lesion_4_num)  # .replace(lesion_4)\n",
    "test['lesion_2_4_num'] = test['lesion_2'].apply(lesion_4_num)  # .replace(lesion_4)\n",
    "\n",
    "train['lesion_1_tot']=train['lesion_1_1_num'] +train['lesion_1_2_num']+train['lesion_1_3_num']+train['lesion_1_4_num'] \n",
    "test['lesion_1_tot']=test['lesion_1_1_num'] +test['lesion_1_2_num']+test['lesion_1_3_num']+test['lesion_1_4_num'] \n",
    "\n",
    "train['lesion_2_tot']=train['lesion_2_1_num'] +train['lesion_2_2_num']+train['lesion_2_3_num']+train['lesion_2_4_num'] \n",
    "test['lesion_2_tot']=test['lesion_2_1_num'] +test['lesion_2_2_num']+test['lesion_2_3_num']+test['lesion_2_4_num'] \n",
    "\n",
    "\n",
    "train=train.drop(columns=['lesion_3'])#'lesion_1','lesion_2',\n",
    "test=test.drop(columns=['lesion_3'])\n",
    "\n",
    "test['lesion_2_1']=test['lesion_2_1'].replace({\"Large_Colon_and_Cecum\":\"Large_Colon\"})\n",
    "test['lesion_2_2']=test['lesion_2_2'].replace({\"Inflammation\":\"Other_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map={\n",
    "    \"lived\":0,\n",
    "    \"died\": 1,\n",
    "    \"euthanized\":2\n",
    "}     \n",
    "\n",
    "def encode(y,target_map):\n",
    "    '''\n",
    "    To convert the outputs to numbers\n",
    "    '''\n",
    "    y=np.array(y)\n",
    "    encoded_y=[target_map[f] for f in y]\n",
    "    return encoded_y\n",
    "def decode(y,target_map):\n",
    "    '''To convert the predictions back to classes\n",
    "    '''\n",
    "    y=np.array(y)\n",
    "    reverse_dict={v: k for k, v in target_map.items()}\n",
    "    decoded_y=[reverse_dict[f] for f in y]\n",
    "    return decoded_y\n",
    "def min_max_scaler(train, test, column):\n",
    "    '''\n",
    "    Min Max just based on train might have an issue if test has extreme values, hence changing the denominator uding overall min and max\n",
    "    '''\n",
    "    sc=MinMaxScaler()\n",
    "    \n",
    "    max_val=max(train[column].max(),test[column].max())\n",
    "    min_val=min(train[column].min(),test[column].min())\n",
    "\n",
    "    train[column]=(train[column]-min_val)/(max_val-min_val)\n",
    "    test[column]=(test[column]-min_val)/(max_val-min_val)\n",
    "    \n",
    "    return train,test  \n",
    "\n",
    "def OHE(train_df,test_df,cols,target):\n",
    "    '''\n",
    "    Function for one hot encoding, it first combined the data so that no category is missed and\n",
    "    the category with least frequency can be dropped because of redunancy\n",
    "    '''\n",
    "    combined = pd.concat([train_df, test_df], axis=0)\n",
    "    for col in cols:\n",
    "        one_hot = pd.get_dummies(combined[col])\n",
    "        counts = combined[col].value_counts()\n",
    "        min_count_category = counts.idxmin()\n",
    "        one_hot = one_hot.drop(min_count_category, axis=1)\n",
    "        one_hot.columns=[str(f)+col for f in one_hot.columns]\n",
    "        combined = pd.concat([combined, one_hot], axis=\"columns\")\n",
    "        combined = combined.loc[:, ~combined.columns.duplicated()]\n",
    "    \n",
    "    # split back to train and test dataframes\n",
    "    train_ohe = combined[:len(train_df)]\n",
    "    test_ohe = combined[len(train_df):]\n",
    "    test_ohe.reset_index(inplace=True,drop=True)\n",
    "    test_ohe.drop(columns=[target],inplace=True)\n",
    "    return train_ohe, test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [f for f in train.columns if train[f].nunique() / train.shape[0] * 100 <= 5 \\\n",
    "            and f not in ['outcome']+cont_cols+ unimportant_features and \"num\" not in f and \"_tot\" not in f]\n",
    "\n",
    "\n",
    "# '''Combine categories with 100% target'''\n",
    "lesion2_map={\n",
    "    3112:3111,\n",
    "    6111:3111,\n",
    "    7112:3111\n",
    "}\n",
    "train['lesion_2']=train['lesion_2'].replace(lesion2_map)\n",
    "test['lesion_2']=test['lesion_2'].replace(lesion2_map)\n",
    "\n",
    "train['pain']=train['pain'].replace({'moderate':'slight'})\n",
    "test['pain']=test['pain'].replace({'moderate':'slight'})\n",
    "\n",
    "\n",
    "for col in cat_cols:\n",
    "    if train[col].dtype==\"O\":\n",
    "        train[col]=train[col].astype(str)+\"_\"+col\n",
    "        test[col]=test[col].astype(str)+\"_\"+col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
